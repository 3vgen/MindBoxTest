{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-10-20T18:58:16.842118Z","iopub.status.busy":"2025-10-20T18:58:16.841862Z","iopub.status.idle":"2025-10-20T18:58:16.848255Z","shell.execute_reply":"2025-10-20T18:58:16.847288Z","shell.execute_reply.started":"2025-10-20T18:58:16.842097Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","from pyspark.sql import DataFrame, SparkSession\n","from pyspark.sql.functions import col\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2025-10-20T18:58:47.507022Z","iopub.status.busy":"2025-10-20T18:58:47.506120Z","iopub.status.idle":"2025-10-20T18:58:47.513977Z","shell.execute_reply":"2025-10-20T18:58:47.512653Z","shell.execute_reply.started":"2025-10-20T18:58:47.506976Z"},"trusted":true},"outputs":[],"source":["from pyspark.sql import DataFrame, SparkSession\n","from pyspark.sql.functions import col\n","\n","def product_category_pairs(\n","    products: DataFrame,\n","    categories: DataFrame,\n","    product_categories: DataFrame\n",") -> DataFrame:\n","    \"\"\"Метод который соединяет продукты с категориями\n","        через промежуточную таблицу многие ко многим\n","    \"\"\"\n","    \n","    pro_cat_with_cat = product_categories.join(\n","        categories, on=\"category_id\", how=\"left\"\n","    )\n","\n","    # Соединяем все продукты с их категориями (или None, если категорий нет)\n","    result = products.join(\n","        pro_cat_with_cat, on=\"product_id\", how=\"left\"\n","    ).select(\n","        col(\"product_name\"),\n","        col(\"category_name\")\n","    )\n","\n","    return result\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2025-10-20T18:58:50.386847Z","iopub.status.busy":"2025-10-20T18:58:50.386281Z","iopub.status.idle":"2025-10-20T18:59:08.061551Z","shell.execute_reply":"2025-10-20T18:59:08.060297Z","shell.execute_reply.started":"2025-10-20T18:58:50.386820Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting default log level to \"WARN\".\n","To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n","25/10/20 18:58:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n","                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["+------------+-------------+\n","|product_name|category_name|\n","+------------+-------------+\n","|        cake|         Food|\n","|       Apple|         Food|\n","|       Apple|        Fruit|\n","|      Orange|         Food|\n","|      Orange|        Fruit|\n","|      Banana|        Fruit|\n","|car magazine|         NULL|\n","+------------+-------------+\n","\n"]}],"source":["spark = SparkSession.builder.master(\"local[1]\").appName(\"Test\").getOrCreate()\n","\n","products = spark.createDataFrame(\n","    [(1, \"Apple\"), (2, \"Banana\"), (3, \"Orange\"), (4, \"car magazine\"), (5, \"cake\")],\n","    [\"product_id\", \"product_name\"]\n",")\n","\n","categories = spark.createDataFrame(\n","    [(10, \"Fruit\"), (20, \"Food\"), (30, \"Electronics\")],\n","    [\"category_id\", \"category_name\"]\n",")\n","\n","product_categories = spark.createDataFrame(\n","    [(1, 10), (2, 10), (1, 20), (3, 10), (3, 20), (5, 20)], \n","    [\"product_id\", \"category_id\"]\n",")\n","\n","df = product_category_pairs(products, categories, product_categories)\n","df.show()\n"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2025-10-20T18:59:29.373075Z","iopub.status.busy":"2025-10-20T18:59:29.371883Z","iopub.status.idle":"2025-10-20T18:59:29.380447Z","shell.execute_reply":"2025-10-20T18:59:29.379315Z","shell.execute_reply.started":"2025-10-20T18:59:29.373036Z"},"trusted":true},"outputs":[],"source":["#test_product_categories.py\n","import pytest\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col\n","\n","@pytest.fixture(scope=\"module\")\n","def spark():\n","    return SparkSession.builder.master(\"local[1]\").appName(\"test\").getOrCreate()\n","\n","def test_product_category_pairs(spark):\n","\n","    products = spark.createDataFrame(\n","        [(1, \"Apple\"), (2, \"Banana\"), (3, \"Orange\")],\n","        [\"product_id\", \"product_name\"]\n","    )\n","\n","    categories = spark.createDataFrame(\n","        [(10, \"Fruit\"), (20, \"Food\")],\n","        [\"category_id\", \"category_name\"]\n","    )\n","\n","    product_categories = spark.createDataFrame(\n","        [(1, 10), (2, 10), (1, 20)],\n","        [\"product_id\", \"category_id\"]\n","    )\n","\n","    result = product_category_pairs(products, categories, product_categories)\n","    rows = result.collect()\n","\n","    expected = set([\n","        (\"Apple\", \"Fruit\"),\n","        (\"Apple\", \"Food\"),\n","        (\"Banana\", \"Fruit\"),\n","        (\"Orange\", None)\n","    ])\n","    actual = set((r.product_name, r.category_name) for r in rows)\n","    assert actual == expected\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31153,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"}},"nbformat":4,"nbformat_minor":4}
